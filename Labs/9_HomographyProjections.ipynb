{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46dc767f",
   "metadata": {},
   "source": [
    "# CSCI E-25      \n",
    "## Homography and Projection \n",
    "### Steve Elston"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a7ef0",
   "metadata": {},
   "source": [
    "## Introduction   \n",
    "\n",
    "Transformation or projection of images is a fundamental and essential method in computer vision. Many CV applications, such as image stitching and stereo vision, require projection methods. \n",
    "\n",
    "In these exercises our primary focus is on projection using the extrinsic matrix. You will apply three types of commonly used extrinsic and one intrinsic transformation to an image:    \n",
    "1. **Euclidean**, rotation and translation. \n",
    "2. **Similarity**, rotation, translation and scale.\n",
    "3. **Affine**,  rotation, translation, scale and shear. \n",
    "4. **Intrinsic camera parameters**, focal length. \n",
    "\n",
    "Before starting the exercises execute the code in the cell below to import the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage \n",
    "from skimage import data\n",
    "from skimage.filters.rank import equalize\n",
    "import skimage.filters as skfilters\n",
    "import skimage.morphology as morphology\n",
    "import skimage.transform as transform\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import exposure\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa371554",
   "metadata": {},
   "source": [
    "## Load and Prepare the Image \n",
    "\n",
    "For these exercises you will work with a gray scale image. Execute the code in the cell below to load the image and display it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ea697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grayscale(img, h=8):\n",
    "    plt.figure(figsize=(h, h))\n",
    "    _=plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "camera_image = data.camera() \n",
    "print('Image size = ' + str(camera_image.shape))\n",
    "plot_grayscale(camera_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df5282",
   "metadata": {},
   "source": [
    "To make the process of visualizing the transformations of image easier a dark margin will be added to the image. Execute the code in the cell below to place the image on the background and to display the result.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbdf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_margin = 256\n",
    "background = np.zeros((camera_image.shape[0] + 2*half_margin, camera_image.shape[1] + 2*half_margin)).astype('int')\n",
    "print('Shape of the background = ' + str(background.shape))\n",
    "\n",
    "camera_image_background = background\n",
    "#camera_image_background[2*half_margin:camera_image_background.shape[0], 0:camera_image_background.shape[1]-2*half_margin] = camera_image\n",
    "camera_image_background[half_margin:camera_image_background.shape[0] - half_margin, half_margin:camera_image_background.shape[1]-half_margin] = camera_image\n",
    "plot_grayscale(camera_image_background)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fcc25c",
   "metadata": {},
   "source": [
    "> **Note:** Unless otherwise specified, use this gray scale image for the following exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8df4d",
   "metadata": {},
   "source": [
    "## Euclidean Transformation\n",
    "\n",
    "The Euclidean transformation involves only rotation and translation. The shape of objects is preserved by the Euclidean transformation.     \n",
    "\n",
    "> **Exercise 9-1:** You will now apply the Euclidean transformation to the image with the margin background. Perform the following steps:   \n",
    "> 1. Create the transformation matrix for a rotation of $\\pi/8$, with no translation, using homogeneous coordinates.   \n",
    "> 2. Display the transformation matrix.  \n",
    "> 3. Apply your transformation matrix to the image using the [skimage.transform.warp](https://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.warp) function, and display the result. You can see the conventions used by Scikit-Image in the documentation for the [skimage.transform.EuclideanTransform](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.EuclideanTransform) function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63446c2e",
   "metadata": {},
   "source": [
    "> 4. Next create a new Numpy transformation matrix in homogeneous coordinates with the same rotation of $\\pi/8$, but with a translation vector of of $[256, -128]^T$. \n",
    "> 5. Display the new transformation matrix.   \n",
    "> 6. Apply your transformation matrix to the image and display the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40cc74",
   "metadata": {},
   "source": [
    "> 7. Finally, you can check your transformation matrix by using the [skimage.transform.EuclideanTransform](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.EuclideanTransform) function, using the rotation angle and translation vector. Compute and display the transformation matrix, in homogeneous coordinates, using the arguments specified in step 4 of this exercise.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9e07c",
   "metadata": {},
   "source": [
    "> In one or two sentences answer the following questions:   \n",
    "> 1. Examine the image displayed in step 3. Keeping in mind that the origin of the image display is in the upper left corner, does the rotated image appear as you expected and why?  \n",
    "> 2. How does the addition of a translation change the result of the transformation.   \n",
    "> 3. Compare the transformation matrix you computed for step 4 with the matrix computed in step 7. Are these transformation matrices the same?  \n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88dab0",
   "metadata": {},
   "source": [
    "> **Answers:** \n",
    "> 1.     \n",
    "> 2.      \n",
    "> 3.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4b987",
   "metadata": {},
   "source": [
    "## Similarity Transform\n",
    "\n",
    "You will now extend the generality of the transformation by adding a change of scale. A similarity transformation can perform rotation, translation as scale. The like the Euclidean transform, the similarity transform preserves shape.   \n",
    "\n",
    "> **Exercise 9-2:**  You will now do the following to explore the properties of the similarity transform: \n",
    "> 1. Create a Numpy transformation matrix in homogeneous coordinates with:  \n",
    ">   - Rotation of $\\pi/8$.  \n",
    ">   - Translation vector of of $[128,0]^T$.   \n",
    ">   - Scale of 0.5. Keep in mind that the scale argument to the `transform.warp` function is applied as $1.0/scale$ to each of the rotation matrix elements. The covention used for similarity transforms in Scikit-Image can be found in the documentation of the [skimage.transform.SimilarityTransform](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.SimilarityTransform) function.    \n",
    "> 2. Display the transformation matrix.   \n",
    "> 3. Apply your transformation matrix to the image and display the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b191c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a08c85",
   "metadata": {},
   "source": [
    "> 4. You can check your transformation matrix by using the [skimage.transform.SimilarityTransform](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.SimilarityTransform) function, using the rotation angle, translation vector and scale (using the inverse). Compute and display the transformation matrix, in homogeneous coordinates, using the arguments specified in step 1 of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb1ae2e",
   "metadata": {},
   "source": [
    "> In one or two sentences answer the following questions. \n",
    "> 1. Compare the image size and shape against the original image size. Does the transform appear to be correctly applied and why?   \n",
    "> 2. Is the homogeneous transformation matrix you computed identical to the one computed with the `SimilarityTransform` function? \n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf86ce",
   "metadata": {},
   "source": [
    "> **Answer:** \n",
    "> 1.    \n",
    "> 2.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2eebfd",
   "metadata": {},
   "source": [
    "## Affine Transform\n",
    "\n",
    "Continuing to generalize the transformation you will now add a shear factor to the transformation. An affine transformation can perform rotation, translation, scaling and shear. The affine transformation preserves parallel lines.   \n",
    "\n",
    "> **Exercise 9-3:**  You will now do the following to explore the properties of the affine transform following the convention used in the [skimage.transform.AffineTransform](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.AffineTransform) function: \n",
    "> 1. Create a Numpy transformation matrix in homogeneous coordinate with:   \n",
    ">   - Rotation of $\\pi/8$. Keep in mind that the scale is applied as $1.0/scale$ to each of the rotation matrix elements.  \n",
    ">   - Translation vector of $[256,-256]^T$. The first element of the inverse scale is applied to the x-axis rotations and the second element to the y-axis rotations.   \n",
    ">   - Scale vector of $[0.8, 0.4]$.   \n",
    ">   - Shear angle of $\\pi/6$. Shear is added to the y-axis rotation angle.   \n",
    "> 2. Display the transformation matrix.   \n",
    "> 3. Apply your transformation matrix to the image and display the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ac67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea224e",
   "metadata": {},
   "source": [
    "> 4. You can check your transformation matrix by using the [skimage.transform.AffineTransform](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.AffineTransform) function, using the rotation angle, translation vector and scale (not the inverse). Compute and display the transformation matrix, in homogeneous coordinates, using the arguments specified in step 1 of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f50d0",
   "metadata": {},
   "source": [
    "> In one or two sentences answer the following questions. \n",
    "> 1. Compare the image size and shape against the original image size. Does the transform appear to be correctly applied and why?   \n",
    "> 2. Is the homogeneous transformation matrix you computed identical to the one computed with the `AffineTransform` function? \n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273d1b7",
   "metadata": {},
   "source": [
    "> **Answer:** \n",
    "> 1.      \n",
    "> 2.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781a681",
   "metadata": {},
   "source": [
    "## Working with the Intrinsic Matrix\n",
    "\n",
    "Up until now, you have been working only with the **extrinsic transformation matrix**, which defines the projection of an object on the image plane. The extrinsic properties of are also known as **camera pose**. These transformations do not account for inernal camera parameters.   \n",
    "\n",
    "The **intrinsic matrix** is used to model camera specific characteristics. Here we will only deal with one camera parameter, the focal length. Focal length is typically denoted $[\\phi_x, \\phi_y]$, for the x and y components, which can be independent. The differences in x and y can arrise for a number of reasons, such as asymmetry of the camera sensor. In Cartesian coordinates, for a basic pinhole camera the object location, $[x,y,w]$, maps to the $[x,y]$ location on the image plane by the following relationships:   \n",
    "\n",
    "$$[x,y] = \\Bigg[\\frac{\\phi_x\\ u}{w},\\frac{\\phi_y\\ v}{w} \\Bigg]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd59c309",
   "metadata": {},
   "source": [
    "> **Exercise 9-4:** You will now apply an intrinsic matrix for two different camera focal lengths by the following steps:  \n",
    "> 1. Define a Numpy extrinsic transform matrix in homogeneous coordinates with rotation $= 0$, translation $[-512,-512]$, no rotation, no scaling, and no shear.  \n",
    "> 2. Define an intrinsic matrix in homogeneous coordinates with focal length $[\\omega_x, \\omega_y]=[2.0, 2.0]$, array offset of 0, and skew correction of 0.  \n",
    "> 3. Perform matrix multiplication between the transform matrix by the intrinsic matrix using [numpy.dot](https://numpy.org/doc/stable/reference/generated/numpy.dot.html).\n",
    "> 4. Print the resulting product of the transformation matrix. \n",
    "> 5. Apply the resulting transformation product to the image and display the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd043f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb633dc",
   "metadata": {},
   "source": [
    "> 6. Define a Numpy extrinsic transform matrix in homogeneous coordinates with rotation $= 0$, translation $[256,256]$, no roation, no scaling, and no shear.  \n",
    "> 7. Define an intrinsic matrix in homogeneous coordinates with focal length $[\\omega_x, \\omega_y]=[0.5, 0.5]$, array offset of 0, and skew correction of 0.  \n",
    "> 8. Perform matrix multiplication between the transform matrix by the intrinsic matrix using [numpy.matmul](https://numpy.org/de/stable/reference/generated/numpy.matmul.html).\n",
    "> 9. Print the resulting product of the transformation matrix. \n",
    "> 10. Apply the resulting transformation product to the image and display the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fad554",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d915755",
   "metadata": {},
   "source": [
    "> In one or two sentences answer the following questions.  \n",
    "> 1. Examine the upper left 4 elements of the first complete transformation matrix for focal length of 2.0. What does the diagonal and off diagonal elements of these terms tell you about the properties of the resulting transformed image?  \n",
    "> 2. Examine the first transformed image. Does this image appear as it should and why? \n",
    "> 3. Examine the upper left 4 elements of the second complete transformation matrix for focal length of 0.5. What does the diagonal and off diagonal elements of these terms tell you about the properties of the resulting transformed image? \n",
    "> 4. Examine the second transformed image. When compared to the image with focal length of 2.0 is the transformed image with focal length of 0.5 consistent with the change in focal length? \n",
    "> **End of exercise**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bda4a7",
   "metadata": {},
   "source": [
    "> **Answers:**  \n",
    "> 1.      \n",
    "> 2.      \n",
    "> 3.    \n",
    "> 4.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9637d",
   "metadata": {},
   "source": [
    "## Projective transform\n",
    "\n",
    "Projective transforms are the most general planar transformations. Here we will only deal with some simple examples, which are equivalent to changing the camera position. \n",
    "\n",
    "In homogenous coordinates, we define the projective transformation matrix as the product of the intrinsic matrix and the extrinsic matrix:  \n",
    "\n",
    "$$\n",
    "\\Omega \\Lambda = \n",
    "\\begin{bmatrix}\n",
    "   \\phi_{11}  & \\phi_{12} & \\phi_{13} \\\\\n",
    "    \\phi_{21}  & \\phi_{22} & \\phi_{23} \\\\\n",
    "    \\phi_{31}  & \\phi_{32} & \\phi_{33}\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "   \\phi_1  & \\gamma & \\delta_x \\\\\n",
    "   0  & \\phi_2 & \\delta_y \\\\\n",
    "    0  & 0 & D\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "   \\omega_{11}  & \\omega_{12} & \\tau_x \\\\\n",
    "    \\omega_{21}  & \\omega_{22} & \\tau_y \\\\\n",
    "    \\omega_{31}  & \\omega_{32} & \\tau_z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For the following exercise you will work with a picture of a piece of furniture in the interior of a house. To load and prepare this image execute the code in the cell below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chest = Image.open('../datafiles/chest.JPG')\n",
    "chest = np.array(chest)\n",
    "print('Iinital image shape = ' + str(chest.shape))\n",
    "\n",
    "chest = rgb2gray(chest)\n",
    "chest = transform.resize(chest, (300,400))\n",
    "print('Final image shape = ' + str(chest.shape))\n",
    "\n",
    "plot_grayscale(chest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515fc706",
   "metadata": {},
   "source": [
    "For the following exercises, you will compute a full projective transform matix as the product of an intrinsic matrix and an extrinsic matrix. You will then apply the projective transform to the image shown above.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee59e0",
   "metadata": {},
   "source": [
    "> **Exercise 9-5:** As a first step to get a feel for projective transformations, do the following. \n",
    "> 1. Create an intrinsic camera matrix as a Numpy array with 1.0 on the diagonal and 0.0 everywhere else, or a $3 \\times 3$ identify matrix.  \n",
    "> 2. Create an extrinsic Numpy transformation matrix with the following properties:    \n",
    ">   - Scale $= 1.0$       \n",
    ">   - $[\\tau_x, \\tau_y] = [-32,0]$\n",
    ">   - The lower left element $=-0.001$, which roughly speaking moves the camera pose horizonatally             \n",
    ">   - No rotation or shear    \n",
    "> 3. Compute and print the fully projective transformation matrix. \n",
    "> 4. Apply the transformation matrix to the chest image and display the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c95493",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e0269c",
   "metadata": {},
   "source": [
    "> Answer the following quesitons:   \n",
    "> 1. In one or two sentences, how can you qualitatively describe the change in the apparent camera pose with respect to the original image resulting from this transformation?  \n",
    "> 2. Examine the projective transformation marix. Given the simple diagonal structure of the intrinsic camera matrix, is this result expected and why?    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a094",
   "metadata": {},
   "source": [
    "> **Answers:**     \n",
    "> 1.      \n",
    "> 2.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4006cdbb",
   "metadata": {},
   "source": [
    "> **Exercise 9-6:** To continue your exploration of the projective transform, do the following. \n",
    "> 1. Create an intrinsic camera matrix as a Numpy array with 1.0 on the diagonal and 0.0 everywhere else.  \n",
    "> 2. Create an extrinsic Numpy transformation matrix with the following properties:    \n",
    ">   - Scale $= 0.6$       \n",
    ">   - $[\\tau_x, \\tau_y] = [-64,0]$\n",
    ">   - The lower left element $=-0.001$, which roughly speaking moves the camera pose horizonatally  \n",
    ">   - The lower middle element $= 0.002$, which roughtly speaking moves the camera pose vertically   \n",
    ">   - No rotation or shear     \n",
    "> 3. Compute and print the fully projective transformation matrix. \n",
    "> 4. Apply the transformation matrix to the chest image and display the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b56510",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba383af",
   "metadata": {},
   "source": [
    "> In one or two sentences, how can you qualitatively describe the change in the apparent camera pose with respect to the original image resulting from this transformation? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ee269",
   "metadata": {},
   "source": [
    "> **Answer:**     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579c108",
   "metadata": {},
   "source": [
    "> **Exercise 9-7:** To continue your exploration of the projective transform, do the following. \n",
    "> 1. Create an intrinsic camera matrix as a Numpy array with 1.0 on the diagonal and 0.0 everywhere else, except a shear $= -0.3$.  \n",
    "> 2. Create an extrinsic Numpy transformation matrix with the following properties:      \n",
    ">    - Scale $= 0.5$       \n",
    ">    - $[\\tau_x, \\tau_y] = [-128,16]$\n",
    ">    - The lower left element $=-0.001$, which roughly speaking moves the camera pose horizonatally  \n",
    ">    - The lower middle element $= 0.002$, which roughtly speaking moves the camera pose vertically   \n",
    ">    - Rotation angle of $\\pi/20.0$    \n",
    ">    - Shear $=-0.3$\n",
    "> 3. Compute and print the fully projective transformation matrix. \n",
    "> 4. Apply the transformation matrix to the chest image and display the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your code below\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524065a",
   "metadata": {},
   "source": [
    "> Answer the following quesitons:   \n",
    "> 1. In one or two sentences, how can you qualitatively describe the change in the apparent camera pose with respect pose in the pervious exercise?  \n",
    "> 2. Examine the projective transformation marix. How does this matrix differ from the one you examined for Exercise 8.5 and what does this tell you about the non-linearity of the response to parameters of the extrinsic matrix?    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaebcf9",
   "metadata": {},
   "source": [
    "> **Answers:**     \n",
    "> 1.       \n",
    "> 2.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3f55a",
   "metadata": {},
   "source": [
    "####  Copyright 2022, 2023, Stephen F Elston. All rights reserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9e8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
